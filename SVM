#This code file uses an SVM model to validate the data, 
#Obtain the accuracy of the optimal model and training set, the accuracy of the validation set, and the training loss
from sklearn import svm
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.model_selection import cross_val_score, StratifiedKFold
import pandas as pd
import os
import numpy as np
import pandas as pd
from sklearn import svm
from sklearn.metrics import classification_report
from sklearn.model_selection import cross_val_predict
from sklearn.model_selection import StratifiedKFold
import numpy as np
import random
import matplotlib.pyplot as plt
import seaborn as sns 

def extract_data_from_excel(folder_path, num_files=500, num_data_points=25):
    data_array = []
    file_names = os.listdir(folder_path)

    selected_file_names = random.sample(file_names, num_files)

    for file_name in selected_file_names:
        file_path = os.path.join(folder_path, file_name)

        df = pd.read_excel(file_path)

        data = df.iloc[:, 1].values

        data_array.append(data)

    data_array = pd.DataFrame(data_array).to_numpy()

    return data_array

folder_path = r'sheep\D'
down_data = extract_data_from_excel(folder_path)

folder_path_stand = r'sheep\S'
stand_data = extract_data_from_excel(folder_path_stand)

folder_path_walk = r'sheep\W'
walk_data = extract_data_from_excel(folder_path_walk)

all_data = np.concatenate((down_data, stand_data, walk_data), axis=0)
X = all_data[:, :]

# Create labels for the two classes
down_labels = np.zeros(down_data.shape[0])
stand_labels = np.ones(stand_data.shape[0])
walk_labels = 2 * np.ones(walk_data.shape[0])
y = np.concatenate((down_labels,stand_labels, walk_labels))

print("数据X shape:", X.shape)
print("标签y shape:", y.shape)

# Create an SVM classifier
clf = svm.SVC(kernel='linear', C=1.0)

# Using StratifiedKFold for 5-fold cross validation
skf = StratifiedKFold(n_splits=5)
report_list = []  

best_accuracy = 0.0
best_model = None

for fold, (train_idx, test_idx) in enumerate(skf.split(X, y), start=1):
    X_train, X_test = X[train_idx], X[test_idx]
    y_train, y_test = y[train_idx], y[test_idx]

    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    
    # Calculation accuracy
    accuracy = np.mean(y_pred == y_test)
    print(f"第{fold}折的准确率: {accuracy:.2f}")

    # If the accuracy of the current model is higher, update the best model
    if accuracy > best_accuracy:
        best_accuracy = accuracy
        best_model = clf

    report = classification_report(y_test, y_pred, output_dict=True)
    report_df = pd.DataFrame(report).transpose()

    # Save classification reports to an Excel file (one file per fold)
    report_filename = f"fold_{fold}_classification_report_github.xlsx"
    report_df.to_excel(report_filename)
    print(f"第{fold}折的分类报告已保存到 {report_filename} 文件中.")
    report_list.append(report_df)

# Merge 5-fold cross validation classification reports and calculate overall classification reports告
combined_report = pd.concat(report_list)
total_report = combined_report.groupby(level=0).mean()
total_report = total_report.append(pd.DataFrame(combined_report.mean()).T, ignore_index=True)

# Save the overall classification report to an Excel file
total_report_filename = "total_classification_report_github.xlsx"
total_report.to_excel(total_report_filename, index=False)
print(f"总体分类报告已保存到 {total_report_filename} 文件中.")

# Using the best model for prediction
if best_model is not None:
    y_pred_all = best_model.predict(X)  # Use the best model to predict all data
    cm = confusion_matrix(y, y_pred_all)

    row_sums = cm.sum(axis=1, keepdims=True)
    normalized_conf_matrix = cm / row_sums
    
    plt.rcParams['font.family'] = 'Times New Roman'
    font = {'size': 20}  
    plt.rc('font', **font)

    # Visual Confusion Matrix
    classes = ["Down", "Stand", "Walk"]  
    disp = ConfusionMatrixDisplay(confusion_matrix=normalized_conf_matrix, display_labels=classes)
    disp.plot(cmap=plt.cm.Blues, values_format='.2f')  
    plt.show()
